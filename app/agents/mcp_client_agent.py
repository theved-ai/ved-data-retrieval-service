from datetime import timedelta
from typing import AsyncGenerator
from agents.mcp import MCPServerStreamableHttp
from agents import Agent, Runner, ItemHelpers
from app.agents.base import AgentBase
from app.dto.agent_request_dto import AgentRequestDto
from app.dto.agent_stream_chunk import AgentStreamChunk


class MCPClientAgent(AgentBase):

    async def execute(
        self, req: AgentRequestDto
    ) -> AsyncGenerator[AgentStreamChunk, None]:
        async with MCPServerStreamableHttp(
            name="MCP Server",
            cache_tools_list=True,
            params={
                "url": "http://localhost:8080/mcp",
                "timeout": timedelta(minutes=10),
                "headers": {"user_uuid": "ec6a607d-c9c5-449e-9efa-db160c08148f"},
            },
            client_session_timeout_seconds=10000,
        ) as mcp_server:
            mcp_client_agent = Agent(
                name="MCP AI Agent",
                instructions="You are an expert virtual assistant capable of interacting with both Slack, gmail and calendar services via the MCP server",
                mcp_servers=[mcp_server],
            )
            result = Runner.run_streamed(mcp_client_agent, req.user_prompt)
            async for event in result.stream_events():
                # Ignore low-level or debug events
                if event.type == "raw_response_event" and event.data.type == "response.in_progress":
                    continue

                # Tool call event: agent decided to call a tool (e.g., Slack, Gmail)
                elif (
                    event.type == "run_item_stream_event"
                    and event.item.type == "tool_call_item"
                ):
                    yield AgentStreamChunk(
                        #data_source=event.item.raw_item.name,  # Name of tool, e.g., "slack"
                        content=f"Calling tool: {event.item.raw_item.name}",
                        #event_type="tool_call",
                    )

                # Tool output event: result from the tool call
                elif (
                    event.type == "run_item_stream_event"
                    and event.item.type == "tool_call_output_item"
                ):
                    yield AgentStreamChunk(
                        #data_source=event.item.type,  # e.g., "slack"
                        content=event.item.output,
                        #event_type="tool_call_output",
                    )

                # LLM message event: content generated by the agent's LLM
                elif (
                    event.type == "run_item_stream_event"
                    and event.item.type == "message_output_item"
                ):
                    yield AgentStreamChunk(
                        #data_source="assistant",
                        content=ItemHelpers.text_message_output(event.item),
                        #event_type="llm_output",
                    )
